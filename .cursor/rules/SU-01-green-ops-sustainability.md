# Rule 19A: Green Operations & Sustainability

<!-- Cursor_RuleID: 19A-green-ops-sustainability -->
<!-- Cursor_Context: Sustainability engineering, environmental impact reduction, carbon-efficient operations -->

## ðŸ“Œ **Rule Statement**

All software systems SHALL implement sustainable engineering practices to minimize environmental impact through carbon-efficient operations, energy optimization, and green computing principles.

## ðŸŽ¯ **Scope & Applicability**

**Applies to:**
- All software applications and services
- Cloud infrastructure and deployment strategies
- CI/CD pipelines and build processes
- Data center operations and resource utilization
- Development workflows and practices

**Criticality:** HIGH - Environmental responsibility and cost optimization

**Role Alignment:**
- **Platform Engineers**: Implement carbon-aware infrastructure
- **DevOps Engineers**: Optimize deployment for energy efficiency
- **Software Engineers**: Write energy-efficient code
- **Data Engineers**: Implement green data processing patterns
- **Product Managers**: Define sustainability requirements

---

## ðŸ“‹ **Rule Requirements**

### **19A.1 Carbon Budget Management**

**Requirement**: Every application MUST define and enforce carbon budgets for workloads.

**Implementation Standards:**
```yaml
# Carbon budget configuration
carbon_budget:
  application: "my-service"
  environment: "production"
  
  # Carbon limits (gCO2eq)
  budgets:
    daily_limit: 5000        # grams CO2 equivalent per day
    monthly_limit: 150000    # grams CO2 equivalent per month
    per_request_limit: 0.5   # grams CO2 equivalent per request
    
  # Monitoring thresholds
  alerts:
    warning_threshold: 80    # % of budget
    critical_threshold: 95   # % of budget
    
  # Carbon intensity tracking
  regions:
    primary: "us-west-2"     # Low carbon intensity region
    fallback: "eu-west-1"    # Alternative low-carbon region
    avoid: ["us-east-1"]     # High carbon intensity regions
    
  # Workload scheduling
  green_windows:
    - start: "02:00"         # Schedule during low-carbon periods
      end: "06:00"
      timezone: "UTC"
      carbon_intensity_max: 50  # gCO2eq/kWh
```

**Enforcement Mechanisms:**
- Pre-deployment carbon impact assessment
- Real-time carbon budget monitoring
- Automatic workload migration during high-carbon periods
- Carbon cost allocation and reporting

---

### **19A.2 Energy-Efficient Architecture**

**Requirement**: Software architectures MUST be designed for energy efficiency and resource optimization.

**Design Patterns:**

#### **Green Computing Principles**
```python
# Energy-efficient code patterns
import asyncio
import functools
from typing import Optional

class EnergyEfficientService:
    """Service designed for minimal energy consumption"""
    
    def __init__(self):
        self.connection_pool = None
        self.cache = {}
        self.batch_queue = []
        
    @functools.lru_cache(maxsize=1000)
    def cached_computation(self, input_data: str) -> str:
        """Cache expensive computations to reduce energy usage"""
        return self.expensive_operation(input_data)
    
    async def batch_processing(self, items: list) -> list:
        """Batch operations to reduce overhead and energy consumption"""
        # Group similar operations
        batched_results = []
        
        # Process in energy-efficient batches
        for batch in self.chunk_list(items, batch_size=100):
            result = await self.process_batch(batch)
            batched_results.extend(result)
            
            # Allow CPU to cool down between batches
            await asyncio.sleep(0.01)
        
        return batched_results
    
    async def adaptive_scaling(self, current_load: float) -> dict:
        """Implement adaptive scaling based on actual demand"""
        carbon_intensity = await self.get_carbon_intensity()
        
        # Scale down during high carbon periods
        if carbon_intensity > 100:  # gCO2eq/kWh
            scale_factor = 0.7
        else:
            scale_factor = 1.0
        
        return {
            "desired_replicas": max(1, int(current_load * scale_factor)),
            "carbon_intensity": carbon_intensity,
            "scaling_reason": "carbon_optimization"
        }
```

#### **Resource Optimization**
```yaml
# Kubernetes resource optimization
apiVersion: apps/v1
kind: Deployment
metadata:
  name: green-service
  annotations:
    sustainability.io/carbon-budget: "100gCO2eq/day"
    sustainability.io/energy-profile: "low"
spec:
  replicas: 2
  template:
    spec:
      # Use efficient instance types
      nodeSelector:
        node.kubernetes.io/instance-type: "t3.medium"  # Energy efficient
        sustainability.io/carbon-intensity: "low"
      
      # Resource requests based on actual usage
      containers:
      - name: app
        resources:
          requests:
            cpu: "100m"      # Right-sized CPU
            memory: "128Mi"   # Right-sized memory
          limits:
            cpu: "500m"      # Prevent resource waste
            memory: "512Mi"
        
        # Environment-specific optimization
        env:
        - name: JAVA_OPTS
          value: "-Xmx400m -XX:+UseG1GC -XX:+UseStringDeduplication"
        
        # Efficient health checks
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 30    # Less frequent checks
        
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 10
```

---

### **19A.3 Carbon-Aware Deployment**

**Requirement**: Deployment strategies MUST consider carbon intensity and energy efficiency.

**Implementation Framework:**

#### **Carbon-Aware Scheduling**
```python
# Carbon-aware deployment orchestrator
import asyncio
import logging
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime, timedelta

@dataclass
class CarbonIntensityData:
    region: str
    intensity: float  # gCO2eq/kWh
    timestamp: datetime
    forecast: List[float]  # Next 24 hours

@dataclass
class DeploymentRequest:
    service_name: str
    resources_required: Dict[str, float]
    priority: str  # "high", "medium", "low"
    carbon_budget: float  # gCO2eq limit
    deadline: Optional[datetime] = None

class CarbonAwareOrchestrator:
    """Orchestrates deployments based on carbon intensity"""
    
    def __init__(self):
        self.carbon_api = CarbonIntensityAPI()
        self.deployment_queue = []
        
    async def schedule_deployment(self, request: DeploymentRequest) -> Dict:
        """Schedule deployment for optimal carbon efficiency"""
        
        # Get carbon intensity for available regions
        regions_data = await self.get_regional_carbon_data()
        
        # Calculate carbon cost for each region
        carbon_costs = {}
        for region, data in regions_data.items():
            estimated_energy = self.estimate_energy_consumption(
                request.resources_required
            )
            carbon_cost = estimated_energy * data.intensity
            carbon_costs[region] = carbon_cost
        
        # Find best region and timing
        optimal_deployment = await self.find_optimal_deployment(
            request, regions_data, carbon_costs
        )
        
        return optimal_deployment
    
    async def find_optimal_deployment(
        self, 
        request: DeploymentRequest,
        regions_data: Dict[str, CarbonIntensityData],
        carbon_costs: Dict[str, float]
    ) -> Dict:
        """Find optimal deployment strategy"""
        
        best_option = None
        min_carbon_cost = float('inf')
        
        for region, carbon_cost in carbon_costs.items():
            if carbon_cost > request.carbon_budget:
                continue  # Exceeds budget
            
            # Check if we can wait for better carbon conditions
            if request.priority == "low" and not request.deadline:
                optimal_time = await self.find_low_carbon_window(
                    region, regions_data[region]
                )
                if optimal_time:
                    carbon_cost *= 0.7  # Discount for waiting
            
            if carbon_cost < min_carbon_cost:
                min_carbon_cost = carbon_cost
                best_option = {
                    "region": region,
                    "carbon_cost": carbon_cost,
                    "scheduled_time": optimal_time if request.priority == "low" else None,
                    "strategy": "immediate" if request.priority == "high" else "optimized"
                }
        
        return best_option or {"error": "No deployment option within carbon budget"}
    
    async def find_low_carbon_window(
        self, 
        region: str, 
        carbon_data: CarbonIntensityData
    ) -> Optional[datetime]:
        """Find the next low-carbon intensity window"""
        
        current_time = datetime.now()
        forecast_hours = carbon_data.forecast
        
        # Find lowest carbon intensity in next 24 hours
        min_intensity_hour = min(range(len(forecast_hours)), 
                               key=lambda i: forecast_hours[i])
        
        # Only schedule later if carbon savings > 20%
        if forecast_hours[min_intensity_hour] < carbon_data.intensity * 0.8:
            return current_time + timedelta(hours=min_intensity_hour)
        
        return None
    
    def estimate_energy_consumption(self, resources: Dict[str, float]) -> float:
        """Estimate energy consumption based on resources"""
        # Simplified energy estimation model
        cpu_energy = resources.get('cpu', 0) * 2.5  # Watts per CPU core
        memory_energy = resources.get('memory', 0) * 0.0003  # Watts per MB
        storage_energy = resources.get('storage', 0) * 0.0001  # Watts per GB
        
        total_energy = cpu_energy + memory_energy + storage_energy
        return total_energy / 1000  # Convert to kWh
```

#### **Green CI/CD Pipeline**
```yaml
# .github/workflows/green-deployment.yml
name: Green CI/CD Pipeline

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  CARBON_BUDGET_DAILY: "1000"  # gCO2eq
  ENERGY_EFFICIENCY_TARGET: "95"  # percentile

jobs:
  carbon-impact-assessment:
    runs-on: ubuntu-latest
    outputs:
      carbon-cost: ${{ steps.assessment.outputs.carbon-cost }}
      deploy-strategy: ${{ steps.assessment.outputs.strategy }}
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Assess Carbon Impact
      id: assessment
      run: |
        # Calculate estimated carbon cost
        python scripts/carbon-impact-calculator.py \
          --resources-file deployment/resources.yaml \
          --output-format github
    
    - name: Carbon Budget Check
      run: |
        if [ "${{ steps.assessment.outputs.carbon-cost }}" -gt "$CARBON_BUDGET_DAILY" ]; then
          echo "âŒ Deployment exceeds daily carbon budget"
          exit 1
        fi

  energy-efficient-build:
    runs-on: ubuntu-latest
    needs: carbon-impact-assessment
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup Node.js with Energy Optimization
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
    
    - name: Energy-Efficient Build
      run: |
        # Use build optimization for energy efficiency
        npm ci --prefer-offline --no-audit
        npm run build:optimized
        
        # Measure build energy consumption
        npm run measure-build-energy
    
    - name: Optimize Docker Image
      run: |
        # Multi-stage build for smaller images
        docker build -t app:latest -f Dockerfile.optimized .
        
        # Image optimization
        docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
          wagoodman/dive app:latest --ci
    
    - name: Carbon Footprint Report
      run: |
        # Generate carbon footprint report for build
        python scripts/build-carbon-reporter.py \
          --build-duration "${{ github.event.head_commit.timestamp }}" \
          --image-size "$(docker images app:latest --format 'table {{.Size}}')"

  carbon-aware-deployment:
    runs-on: ubuntu-latest
    needs: [carbon-impact-assessment, energy-efficient-build]
    if: needs.carbon-impact-assessment.outputs.deploy-strategy == 'immediate'
    
    steps:
    - name: Deploy to Low-Carbon Region
      run: |
        # Get current carbon intensity
        CARBON_INTENSITY=$(curl -s "https://api.carbonintensity.org.uk/intensity" | jq '.data[0].intensity.actual')
        
        # Choose deployment region based on carbon intensity
        if [ "$CARBON_INTENSITY" -lt "100" ]; then
          DEPLOY_REGION="us-west-2"  # Low carbon region
        else
          DEPLOY_REGION="eu-west-1"  # Alternative low carbon
        fi
        
        # Deploy with carbon-aware configuration
        kubectl apply -f deployment/green-deployment.yaml \
          --context="$DEPLOY_REGION"
        
        # Set up carbon monitoring
        kubectl apply -f monitoring/carbon-monitoring.yaml \
          --context="$DEPLOY_REGION"
    
    - name: Post-Deployment Carbon Tracking
      run: |
        # Start carbon tracking for deployed application
        python scripts/carbon-tracker.py \
          --service-name "${{ github.event.repository.name }}" \
          --deployment-region "$DEPLOY_REGION" \
          --start-tracking
```

---

### **19A.4 Green Data Operations**

**Requirement**: Data processing and storage MUST implement energy-efficient patterns and carbon-aware scheduling.

**Implementation Patterns:**

#### **Energy-Efficient Data Processing**
```python
# Green data processing framework
import asyncio
import pandas as pd
from typing import Iterator, List, Dict, Optional
from dataclasses import dataclass
from datetime import datetime

@dataclass
class CarbonOptimizedDataPipeline:
    """Data pipeline optimized for carbon efficiency"""
    
    def __init__(self, carbon_budget: float):
        self.carbon_budget = carbon_budget  # gCO2eq
        self.current_consumption = 0.0
        self.batch_size_optimizer = BatchSizeOptimizer()
        
    async def process_dataset(
        self, 
        data_source: str, 
        processing_func: callable,
        priority: str = "medium"
    ) -> Dict:
        """Process dataset with carbon awareness"""
        
        # Check carbon budget before processing
        estimated_carbon = await self.estimate_processing_carbon(data_source)
        if estimated_carbon > self.remaining_budget():
            return await self.handle_budget_exceeded(data_source, priority)
        
        # Optimize processing for energy efficiency
        optimal_batch_size = await self.batch_size_optimizer.find_optimal_size(
            data_source, processing_func
        )
        
        # Process with carbon tracking
        results = []
        carbon_consumed = 0.0
        
        async for batch in self.energy_efficient_batches(data_source, optimal_batch_size):
            batch_start_time = datetime.now()
            
            # Process batch
            batch_result = await processing_func(batch)
            results.append(batch_result)
            
            # Track carbon consumption
            batch_carbon = await self.measure_batch_carbon(
                batch_start_time, len(batch)
            )
            carbon_consumed += batch_carbon
            self.current_consumption += batch_carbon
            
            # Adaptive throttling based on carbon budget
            if self.current_consumption > self.carbon_budget * 0.8:
                await asyncio.sleep(1.0)  # Throttle processing
        
        return {
            "results": results,
            "carbon_consumed": carbon_consumed,
            "efficiency_score": len(results) / carbon_consumed if carbon_consumed > 0 else 0
        }
    
    async def energy_efficient_batches(
        self, 
        data_source: str, 
        batch_size: int
    ) -> Iterator[List]:
        """Generate batches optimized for energy efficiency"""
        
        # Implement lazy loading to reduce memory footprint
        data_iterator = self.create_lazy_iterator(data_source)
        
        batch = []
        for item in data_iterator:
            batch.append(item)
            
            if len(batch) >= batch_size:
                yield batch
                batch = []
                
                # Allow CPU to cool down between batches
                await asyncio.sleep(0.05)
        
        # Yield remaining items
        if batch:
            yield batch
    
    def remaining_budget(self) -> float:
        """Calculate remaining carbon budget"""
        return max(0, self.carbon_budget - self.current_consumption)

class BatchSizeOptimizer:
    """Optimizes batch sizes for energy efficiency"""
    
    async def find_optimal_size(
        self, 
        data_source: str, 
        processing_func: callable
    ) -> int:
        """Find batch size that minimizes energy per item processed"""
        
        # Test different batch sizes
        test_sizes = [10, 50, 100, 500, 1000]
        efficiency_scores = {}
        
        for size in test_sizes:
            # Run small test with this batch size
            test_data = await self.get_test_sample(data_source, size)
            
            start_time = datetime.now()
            await processing_func(test_data)
            processing_time = (datetime.now() - start_time).total_seconds()
            
            # Calculate efficiency (items per second per watt)
            energy_estimate = self.estimate_energy(processing_time, size)
            efficiency_scores[size] = size / (processing_time * energy_estimate)
        
        # Return batch size with highest efficiency
        optimal_size = max(efficiency_scores.keys(), 
                          key=lambda k: efficiency_scores[k])
        
        return optimal_size
    
    def estimate_energy(self, processing_time: float, batch_size: int) -> float:
        """Estimate energy consumption for processing"""
        # Simplified energy model
        base_energy = 0.1  # Base CPU energy (watts)
        processing_energy = processing_time * 2.0  # Processing energy
        memory_energy = batch_size * 0.0001  # Memory energy
        
        return base_energy + processing_energy + memory_energy
```

#### **Carbon-Aware Data Storage**
```yaml
# Green data storage configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: green-storage-config
data:
  storage-policy.yaml: |
    # Carbon-aware storage tiering
    storage_tiers:
      hot:
        description: "Frequently accessed data"
        carbon_intensity: "high"
        access_pattern: "real-time"
        retention_days: 30
        storage_class: "ssd"
        
      warm:
        description: "Occasionally accessed data"
        carbon_intensity: "medium"
        access_pattern: "batch"
        retention_days: 365
        storage_class: "hdd"
        
      cold:
        description: "Rarely accessed data"
        carbon_intensity: "low"
        access_pattern: "archive"
        retention_days: 2555  # 7 years
        storage_class: "archive"
        
      frozen:
        description: "Compliance/backup data"
        carbon_intensity: "minimal"
        access_pattern: "emergency"
        retention_days: 3650  # 10 years
        storage_class: "glacier"
    
    # Automatic data lifecycle management
    lifecycle_rules:
      - name: "optimize-for-carbon"
        enabled: true
        rules:
          - condition: "age > 30 days AND access_count < 10"
            action: "move_to_warm"
          - condition: "age > 365 days AND access_count < 2"
            action: "move_to_cold"
          - condition: "age > 2555 days"
            action: "move_to_frozen"
    
    # Data compression and deduplication
    optimization:
      compression:
        enabled: true
        algorithm: "zstd"  # Energy-efficient compression
        level: 3  # Balance between compression ratio and CPU usage
      
      deduplication:
        enabled: true
        window_size: "1GB"
        hash_algorithm: "xxhash"  # Fast, low-energy hash
      
      # Intelligent prefetching
      prefetching:
        enabled: true
        carbon_aware: true
        max_prefetch_carbon: "10gCO2eq"  # Carbon budget for prefetching

---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: carbon-aware-data-optimization
spec:
  schedule: "0 2 * * *"  # Run during low-carbon hours
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: data-optimizer
            image: green-data-optimizer:latest
            env:
            - name: CARBON_INTENSITY_THRESHOLD
              value: "50"  # gCO2eq/kWh
            - name: OPTIMIZATION_LEVEL
              value: "aggressive"
            
            command:
            - /bin/sh
            - -c
            - |
              # Check current carbon intensity
              CARBON_INTENSITY=$(curl -s "${CARBON_API_URL}/current" | jq '.intensity')
              
              if [ "$CARBON_INTENSITY" -lt "$CARBON_INTENSITY_THRESHOLD" ]; then
                echo "âœ… Low carbon intensity detected, running optimization"
                
                # Run data optimization tasks
                python /opt/data-optimizer/optimize_storage.py \
                  --mode=carbon-aware \
                  --target-reduction=20
                
                python /opt/data-optimizer/compress_old_data.py \
                  --age-threshold=90
                
                python /opt/data-optimizer/deduplicate_backups.py \
                  --carbon-budget=50
              else
                echo "â¸ï¸  High carbon intensity, skipping optimization"
              fi
          
          restartPolicy: OnFailure
```

---

### **19A.5 Monitoring & Reporting**

**Requirement**: Systems MUST provide comprehensive carbon footprint monitoring and sustainability reporting.

**Monitoring Implementation:**

#### **Carbon Metrics Dashboard**
```python
# Carbon monitoring and reporting system
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from dataclasses import dataclass
import prometheus_client
from prometheus_client import Counter, Histogram, Gauge

@dataclass
class CarbonMetrics:
    """Carbon footprint metrics"""
    service_name: str
    timestamp: datetime
    carbon_consumed: float  # gCO2eq
    energy_consumed: float  # kWh
    carbon_intensity: float  # gCO2eq/kWh
    region: str
    efficiency_score: float

class CarbonMonitoring:
    """Comprehensive carbon footprint monitoring"""
    
    def __init__(self):
        # Prometheus metrics
        self.carbon_consumption_total = Counter(
            'carbon_consumption_grams_total',
            'Total carbon consumption in grams CO2 equivalent',
            ['service', 'region', 'environment']
        )
        
        self.energy_consumption_total = Counter(
            'energy_consumption_kwh_total',
            'Total energy consumption in kWh',
            ['service', 'region', 'environment']
        )
        
        self.carbon_intensity_current = Gauge(
            'carbon_intensity_gco2_per_kwh',
            'Current carbon intensity in gCO2/kWh',
            ['region']
        )
        
        self.carbon_efficiency_score = Histogram(
            'carbon_efficiency_score',
            'Carbon efficiency score (higher is better)',
            ['service', 'operation_type']
        )
        
        self.carbon_budget_remaining = Gauge(
            'carbon_budget_remaining_percent',
            'Remaining carbon budget as percentage',
            ['service', 'period']  # daily, weekly, monthly
        )
        
        # Initialize carbon tracking
        self.carbon_tracker = CarbonTracker()
        
    async def track_operation_carbon(
        self, 
        service_name: str,
        operation_type: str,
        operation_func: callable,
        *args, **kwargs
    ) -> Dict:
        """Track carbon footprint of an operation"""
        
        start_time = datetime.now()
        start_metrics = await self.carbon_tracker.get_current_metrics()
        
        try:
            # Execute operation
            result = await operation_func(*args, **kwargs)
            
            # Measure carbon impact
            end_time = datetime.now()
            end_metrics = await self.carbon_tracker.get_current_metrics()
            
            carbon_consumed = end_metrics.carbon_consumed - start_metrics.carbon_consumed
            energy_consumed = end_metrics.energy_consumed - start_metrics.energy_consumed
            operation_duration = (end_time - start_time).total_seconds()
            
            # Calculate efficiency score
            efficiency_score = self.calculate_efficiency_score(
                carbon_consumed, energy_consumed, operation_duration
            )
            
            # Update metrics
            self.carbon_consumption_total.labels(
                service=service_name,
                region=end_metrics.region,
                environment=os.getenv('ENVIRONMENT', 'unknown')
            ).inc(carbon_consumed)
            
            self.energy_consumption_total.labels(
                service=service_name,
                region=end_metrics.region,
                environment=os.getenv('ENVIRONMENT', 'unknown')
            ).inc(energy_consumed)
            
            self.carbon_efficiency_score.labels(
                service=service_name,
                operation_type=operation_type
            ).observe(efficiency_score)
            
            return {
                "result": result,
                "carbon_consumed": carbon_consumed,
                "energy_consumed": energy_consumed,
                "efficiency_score": efficiency_score,
                "duration": operation_duration
            }
            
        except Exception as e:
            logging.error(f"Operation failed: {e}")
            raise
    
    def calculate_efficiency_score(
        self, 
        carbon_consumed: float, 
        energy_consumed: float, 
        duration: float
    ) -> float:
        """Calculate carbon efficiency score (0-100)"""
        if carbon_consumed <= 0:
            return 100.0
        
        # Efficiency = work done per unit carbon
        # Higher score means more efficient
        base_score = 100.0
        carbon_penalty = min(carbon_consumed * 10, 50)  # Max 50 point penalty
        energy_penalty = min(energy_consumed * 5, 30)   # Max 30 point penalty
        
        efficiency_score = max(0, base_score - carbon_penalty - energy_penalty)
        return efficiency_score
    
    async def generate_sustainability_report(
        self, 
        service_name: str,
        period_days: int = 30
    ) -> Dict:
        """Generate comprehensive sustainability report"""
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=period_days)
        
        # Collect metrics for the period
        metrics = await self.carbon_tracker.get_metrics_for_period(
            service_name, start_date, end_date
        )
        
        # Calculate sustainability KPIs
        total_carbon = sum(m.carbon_consumed for m in metrics)
        total_energy = sum(m.energy_consumed for m in metrics)
        avg_efficiency = sum(m.efficiency_score for m in metrics) / len(metrics) if metrics else 0
        
        # Carbon trend analysis
        carbon_trend = self.analyze_carbon_trend(metrics)
        
        # Regional carbon breakdown
        regional_breakdown = self.analyze_regional_carbon(metrics)
        
        # Efficiency improvements
        efficiency_recommendations = await self.generate_efficiency_recommendations(
            service_name, metrics
        )
        
        return {
            "service_name": service_name,
            "reporting_period": {
                "start": start_date.isoformat(),
                "end": end_date.isoformat(),
                "days": period_days
            },
            "carbon_footprint": {
                "total_carbon_gco2eq": total_carbon,
                "total_energy_kwh": total_energy,
                "average_carbon_intensity": total_carbon / total_energy if total_energy > 0 else 0,
                "carbon_per_day": total_carbon / period_days,
                "efficiency_score": avg_efficiency
            },
            "trends": carbon_trend,
            "regional_breakdown": regional_breakdown,
            "recommendations": efficiency_recommendations,
            "sustainability_grade": self.calculate_sustainability_grade(
                avg_efficiency, carbon_trend["direction"]
            )
        }
    
    def analyze_carbon_trend(self, metrics: List[CarbonMetrics]) -> Dict:
        """Analyze carbon consumption trends"""
        if len(metrics) < 2:
            return {"direction": "insufficient_data", "change_percent": 0}
        
        # Calculate daily averages
        daily_carbon = {}
        for metric in metrics:
            date_key = metric.timestamp.date()
            if date_key not in daily_carbon:
                daily_carbon[date_key] = []
            daily_carbon[date_key].append(metric.carbon_consumed)
        
        # Calculate trend
        daily_averages = [
            sum(values) / len(values) 
            for values in daily_carbon.values()
        ]
        
        if len(daily_averages) < 2:
            return {"direction": "insufficient_data", "change_percent": 0}
        
        # Simple linear trend
        first_half = sum(daily_averages[:len(daily_averages)//2])
        second_half = sum(daily_averages[len(daily_averages)//2:])
        
        change_percent = ((second_half - first_half) / first_half * 100) if first_half > 0 else 0
        
        if change_percent < -5:
            direction = "improving"
        elif change_percent > 5:
            direction = "degrading"
        else:
            direction = "stable"
        
        return {
            "direction": direction,
            "change_percent": round(change_percent, 2),
            "daily_averages": daily_averages
        }
    
    def calculate_sustainability_grade(
        self, 
        efficiency_score: float, 
        trend_direction: str
    ) -> str:
        """Calculate overall sustainability grade A-F"""
        
        base_score = efficiency_score
        
        # Adjust based on trend
        if trend_direction == "improving":
            base_score += 10
        elif trend_direction == "degrading":
            base_score -= 15
        
        if base_score >= 90:
            return "A"
        elif base_score >= 80:
            return "B"
        elif base_score >= 70:
            return "C"
        elif base_score >= 60:
            return "D"
        else:
            return "F"
```

#### **Carbon Dashboard Configuration**
```yaml
# Grafana dashboard for carbon monitoring
apiVersion: v1
kind: ConfigMap
metadata:
  name: carbon-dashboard-config
data:
  carbon-dashboard.json: |
    {
      "dashboard": {
        "title": "Carbon Footprint & Sustainability",
        "tags": ["sustainability", "carbon", "green-ops"],
        "panels": [
          {
            "title": "Carbon Consumption (Real-time)",
            "type": "graph",
            "targets": [
              {
                "expr": "rate(carbon_consumption_grams_total[5m])",
                "legendFormat": "{{service}} - {{region}}"
              }
            ],
            "yAxes": [
              {
                "label": "gCO2eq/sec",
                "unit": "short"
              }
            ],
            "thresholds": [
              {
                "value": 1.0,
                "colorMode": "critical",
                "op": "gt"
              }
            ]
          },
          {
            "title": "Carbon Budget Utilization",
            "type": "stat",
            "targets": [
              {
                "expr": "carbon_budget_remaining_percent",
                "legendFormat": "{{service}} - {{period}}"
              }
            ],
            "fieldConfig": {
              "thresholds": {
                "steps": [
                  {"color": "green", "value": 80},
                  {"color": "yellow", "value": 50},
                  {"color": "red", "value": 20}
                ]
              }
            }
          },
          {
            "title": "Carbon Intensity by Region",
            "type": "heatmap",
            "targets": [
              {
                "expr": "carbon_intensity_gco2_per_kwh",
                "legendFormat": "{{region}}"
              }
            ]
          },
          {
            "title": "Efficiency Trends",
            "type": "graph",
            "targets": [
              {
                "expr": "histogram_quantile(0.95, carbon_efficiency_score)",
                "legendFormat": "95th Percentile"
              },
              {
                "expr": "histogram_quantile(0.50, carbon_efficiency_score)",
                "legendFormat": "Median"
              }
            ]
          },
          {
            "title": "Green Operations Alerts",
            "type": "alertlist",
            "targets": [
              {
                "expr": "carbon_budget_remaining_percent < 20",
                "alert": "Carbon Budget Critical"
              },
              {
                "expr": "carbon_intensity_gco2_per_kwh > 100",
                "alert": "High Carbon Intensity"
              }
            ]
          }
        ]
      }
    }

---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: carbon-footprint-alerts
spec:
  groups:
  - name: carbon_alerts
    rules:
    - alert: CarbonBudgetExceeded
      expr: carbon_budget_remaining_percent < 10
      for: 5m
      labels:
        severity: critical
        category: sustainability
      annotations:
        summary: "Carbon budget critically low for {{ $labels.service }}"
        description: "Service {{ $labels.service }} has less than 10% of carbon budget remaining"
    
    - alert: HighCarbonIntensity
      expr: carbon_intensity_gco2_per_kwh > 150
      for: 10m
      labels:
        severity: warning
        category: sustainability
      annotations:
        summary: "High carbon intensity in {{ $labels.region }}"
        description: "Carbon intensity in {{ $labels.region }} is {{ $value }} gCO2/kWh"
    
    - alert: CarbonEfficiencyDegraded
      expr: carbon_efficiency_score < 60
      for: 15m
      labels:
        severity: warning
        category: sustainability
      annotations:
        summary: "Carbon efficiency degraded for {{ $labels.service }}"
        description: "Service {{ $labels.service }} efficiency score dropped to {{ $value }}"
```

---

## ðŸ”§ **Implementation Templates**

### **Template 1: Carbon Budget Configuration**
```yaml
# templates/carbon-budget.yaml
carbon_budget:
  application: "{{APPLICATION_NAME}}"
  environment: "{{ENVIRONMENT}}"
  version: "1.0"
  
  # Budget definitions
  budgets:
    daily_limit: {{DAILY_CARBON_LIMIT}}      # gCO2eq
    monthly_limit: {{MONTHLY_CARBON_LIMIT}}  # gCO2eq
    per_request_limit: {{REQUEST_CARBON_LIMIT}} # gCO2eq
    per_user_limit: {{USER_CARBON_LIMIT}}    # gCO2eq per user per day
  
  # Alert thresholds
  alerts:
    warning_threshold: 80    # % of budget
    critical_threshold: 95   # % of budget
    forecast_threshold: 85   # % if current trend continues
  
  # Regional preferences
  regions:
    preferred:
      - region: "{{PRIMARY_REGION}}"
        max_carbon_intensity: 50  # gCO2eq/kWh
      - region: "{{SECONDARY_REGION}}"
        max_carbon_intensity: 75  # gCO2eq/kWh
    
    avoided:
      - region: "{{HIGH_CARBON_REGION}}"
        reason: "High carbon intensity"
        fallback_only: true
  
  # Carbon-aware scheduling
  scheduling:
    enable_carbon_aware: true
    green_hours:
      start: "{{GREEN_WINDOW_START}}"
      end: "{{GREEN_WINDOW_END}}"
      timezone: "{{TIMEZONE}}"
    
    workload_shifting:
      enable: true
      max_delay_hours: {{MAX_DELAY_HOURS}}
      priority_override: ["critical", "high"]
  
  # Reporting
  reporting:
    frequency: "daily"
    stakeholders:
      - email: "{{SUSTAINABILITY_TEAM_EMAIL}}"
        role: "sustainability_lead"
      - email: "{{ENGINEERING_LEAD_EMAIL}}"
        role: "engineering_lead"
    
    include_recommendations: true
    carbon_offset_tracking: true
```

### **Template 2: Green Ops Configuration**
```yaml
# templates/green-ops-config.yaml
green_ops:
  application: "{{APPLICATION_NAME}}"
  sustainability_tier: "{{SUSTAINABILITY_TIER}}"  # basic, standard, advanced
  
  # Energy optimization
  energy_optimization:
    cpu_governor: "powersave"
    memory_optimization: true
    storage_optimization:
      compression: true
      deduplication: true
      tiering: true
    
    network_optimization:
      connection_pooling: true
      request_batching: true
      cdn_optimization: true
  
  # Carbon-aware operations
  carbon_awareness:
    deployment_strategy: "carbon_optimal"
    scaling_policy: "carbon_efficient"
    backup_timing: "low_carbon_windows"
    
    data_processing:
      batch_optimization: true
      off_peak_scheduling: true
      carbon_budget_enforcement: true
  
  # Monitoring and alerts
  monitoring:
    carbon_tracking: true
    energy_monitoring: true
    efficiency_scoring: true
    
    dashboards:
      - name: "carbon_footprint"
        url: "{{GRAFANA_URL}}/carbon-dashboard"
      - name: "energy_efficiency"
        url: "{{GRAFANA_URL}}/energy-dashboard"
  
  # Compliance and reporting
  compliance:
    framework: "{{COMPLIANCE_FRAMEWORK}}"  # ISO14001, GHG Protocol, etc.
    reporting_frequency: "{{REPORTING_FREQUENCY}}"
    audit_trail: true
    
    targets:
      carbon_reduction_yearly: "{{CARBON_REDUCTION_TARGET}}"  # %
      energy_efficiency_improvement: "{{EFFICIENCY_TARGET}}"  # %
      renewable_energy_percentage: "{{RENEWABLE_TARGET}}"     # %
```

### **Template 3: Power Profiling Configuration**
```json
{
  "power_profiling": {
    "application": "{{APPLICATION_NAME}}",
    "profiling_level": "{{PROFILING_LEVEL}}",
    
    "measurement_points": {
      "cpu_usage": {
        "enabled": true,
        "sampling_rate": "{{CPU_SAMPLING_RATE}}",
        "power_model": "linear"
      },
      "memory_usage": {
        "enabled": true,
        "sampling_rate": "{{MEMORY_SAMPLING_RATE}}",
        "power_coefficient": 0.0003
      },
      "storage_io": {
        "enabled": true,
        "read_power_coefficient": 0.5,
        "write_power_coefficient": 1.2
      },
      "network_io": {
        "enabled": true,
        "transmission_power_coefficient": 0.8,
        "reception_power_coefficient": 0.3
      }
    },
    
    "ci_integration": {
      "measure_build_energy": true,
      "measure_test_energy": true,
      "energy_budget_check": true,
      "power_regression_detection": true
    },
    
    "optimization_suggestions": {
      "enabled": true,
      "algorithm_suggestions": true,
      "resource_optimization": true,
      "scheduling_optimization": true
    },
    
    "reporting": {
      "power_profile_report": true,
      "efficiency_trends": true,
      "optimization_impact": true,
      "carbon_correlation": true
    }
  }
}
```

---

## âœ… **Compliance Validation**

### **Automated Checks**
```python
# Carbon compliance validation
async def validate_carbon_compliance(service_config: Dict) -> Dict:
    """Validate compliance with green operations requirements"""
    
    validation_results = {
        "19A.1_carbon_budget": False,
        "19A.2_energy_efficient_architecture": False,
        "19A.3_carbon_aware_deployment": False,
        "19A.4_green_data_operations": False,
        "19A.5_monitoring_reporting": False,
        "overall_compliance": False
    }
    
    # Check carbon budget implementation
    if "carbon_budget" in service_config:
        validation_results["19A.1_carbon_budget"] = validate_carbon_budget(
            service_config["carbon_budget"]
        )
    
    # Check energy-efficient architecture
    if "green_ops" in service_config:
        validation_results["19A.2_energy_efficient_architecture"] = validate_energy_architecture(
            service_config["green_ops"]
        )
    
    # Check carbon-aware deployment
    if "deployment" in service_config:
        validation_results["19A.3_carbon_aware_deployment"] = validate_carbon_deployment(
            service_config["deployment"]
        )
    
    # Check green data operations
    if "data_processing" in service_config:
        validation_results["19A.4_green_data_operations"] = validate_green_data_ops(
            service_config["data_processing"]
        )
    
    # Check monitoring and reporting
    if "monitoring" in service_config:
        validation_results["19A.5_monitoring_reporting"] = validate_carbon_monitoring(
            service_config["monitoring"]
        )
    
    # Calculate overall compliance
    compliance_count = sum(1 for v in validation_results.values() if v and isinstance(v, bool))
    validation_results["overall_compliance"] = compliance_count >= 4  # At least 4/5 requirements
    
    return validation_results
```

### **CI/CD Integration**
```yaml
# CI pipeline for carbon compliance
- name: Carbon Compliance Check
  run: |
    python scripts/carbon-compliance-checker.py \
      --config deployment/green-ops-config.yaml \
      --carbon-budget deployment/carbon-budget.yaml \
      --fail-on-non-compliance
```

---

## ðŸ“š **Additional Resources**

### **Carbon Calculation References**
- [Green Software Foundation](https://greensoftware.foundation/)
- [Carbon Intensity API](https://carbonintensity.org.uk/)
- [Cloud Carbon Footprint](https://www.cloudcarbonfootprint.org/)
- [Energy Efficiency Guidelines](https://www.energy.gov/eere/femp/best-practice-guidelines-energy-efficient-data-center-design)

### **Industry Standards**
- ISO 14001 - Environmental Management Systems
- GHG Protocol - Corporate Accounting and Reporting Standard
- EU Energy Efficiency Directive
- ENERGY STAR for Data Centers

### **Tools and Libraries**
- **Carbon Tracking**: CodeCarbon, Green Algorithms
- **Energy Monitoring**: Intel RAPL, NVIDIA-ML
- **Cloud Carbon APIs**: AWS Carbon Footprint, Google Carbon Intelligence
- **CI/CD Integration**: EcoCode, SonarQube Eco-Code rules

---

*This rule is part of the Universal Development Rules Framework v2.1 - Advancing enterprise governance with sustainability, security, and domain-specific capabilities.* 